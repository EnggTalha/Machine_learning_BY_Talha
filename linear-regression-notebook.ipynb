{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-25T14:20:45.910072Z","iopub.execute_input":"2023-08-25T14:20:45.91052Z","iopub.status.idle":"2023-08-25T14:20:45.923115Z","shell.execute_reply.started":"2023-08-25T14:20:45.910484Z","shell.execute_reply":"2023-08-25T14:20:45.921663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot imports\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:45.925788Z","iopub.execute_input":"2023-08-25T14:20:45.926267Z","iopub.status.idle":"2023-08-25T14:20:45.944736Z","shell.execute_reply.started":"2023-08-25T14:20:45.926205Z","shell.execute_reply":"2023-08-25T14:20:45.943509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#input the data\ntrain_df = pd.read_csv(\"/kaggle/input/random-linear-regression/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/random-linear-regression/test.csv\")\n\nprint(\"Los Geht's\")","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:45.94635Z","iopub.execute_input":"2023-08-25T14:20:45.946974Z","iopub.status.idle":"2023-08-25T14:20:45.972693Z","shell.execute_reply.started":"2023-08-25T14:20:45.946943Z","shell.execute_reply":"2023-08-25T14:20:45.97162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Linear Regression Overview**\n### Define of a Line: is a collection of an infinite number of points extending in two oppsite directions.\n\n### Algebra the equation of a line:\n## $y = mx + b$\n\n### - y is the dependent variable\n### - x is the independent variable\n### - m is the slope which is the amount that y increases or decreases per one unit increase of x\n### - b is the intercept which is the value of y when x is zero. \n\n### Linear Regression: is estimates the linear relationship between a continous dependent variable and one or more independent variables.\n\n### Dependent Variable is normally labeled Y.  The Dependent Variable (Y) is also called the response or outcome variable.\n\n### Independent Variable is normally labeled X. The Independent Variable shows the trends of the Dependent Variable (Y). The Independent Variable is also called explanatory or predictor variable. \n\n### When x and y variables are related in a linear. X and y variable are correlated to each other. \n\n## $y = mx + b + \\epsilon$\n\n### $\\epsilon$ is the error or residuals which is the differences between the observed and predicted values of the points measured to the line.  \n\n","metadata":{}},{"cell_type":"markdown","source":"# **EDA of the data**","metadata":{}},{"cell_type":"code","source":"# Check the shape of both dataframes\ntrain_df.shape, test_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:45.974937Z","iopub.execute_input":"2023-08-25T14:20:45.975262Z","iopub.status.idle":"2023-08-25T14:20:45.985697Z","shell.execute_reply.started":"2023-08-25T14:20:45.975214Z","shell.execute_reply":"2023-08-25T14:20:45.98419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the columns\ntrain_df.columns, test_df.columns","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:45.987666Z","iopub.execute_input":"2023-08-25T14:20:45.98841Z","iopub.status.idle":"2023-08-25T14:20:46.007506Z","shell.execute_reply.started":"2023-08-25T14:20:45.98837Z","shell.execute_reply":"2023-08-25T14:20:46.005503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:46.009508Z","iopub.execute_input":"2023-08-25T14:20:46.009925Z","iopub.status.idle":"2023-08-25T14:20:46.03302Z","shell.execute_reply.started":"2023-08-25T14:20:46.009884Z","shell.execute_reply":"2023-08-25T14:20:46.031336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### There is a null in the y column of the training dataframe. ","metadata":{}},{"cell_type":"code","source":"test_df.info()","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:46.034456Z","iopub.execute_input":"2023-08-25T14:20:46.035407Z","iopub.status.idle":"2023-08-25T14:20:46.054752Z","shell.execute_reply.started":"2023-08-25T14:20:46.035367Z","shell.execute_reply":"2023-08-25T14:20:46.052723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test dataframe has no nulls. ","metadata":{}},{"cell_type":"code","source":"train_df.describe()","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:46.05667Z","iopub.execute_input":"2023-08-25T14:20:46.057684Z","iopub.status.idle":"2023-08-25T14:20:46.080701Z","shell.execute_reply.started":"2023-08-25T14:20:46.057645Z","shell.execute_reply":"2023-08-25T14:20:46.079632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### X column has an outlier in the data max 3530.157369\n### Y column has a NaN in the dataset with a count of 699. \n","metadata":{}},{"cell_type":"code","source":"# Finding the NaN Value\nnan_values = train_df[train_df['y'].isna()]\n\nprint (nan_values)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:46.082024Z","iopub.execute_input":"2023-08-25T14:20:46.082523Z","iopub.status.idle":"2023-08-25T14:20:46.096805Z","shell.execute_reply.started":"2023-08-25T14:20:46.082493Z","shell.execute_reply":"2023-08-25T14:20:46.095331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Row 213 has the outlier in the X column and the Y column has the NaN. \n### Row 213 will be delete since there is an outliear and a NaN in the same row. \n### If 213 row only had a NaN could do a median of the y column and fillna to replace the NaN value. \n","metadata":{}},{"cell_type":"code","source":"# Check for Outliers in the data\ng0 =sns.boxplot(data=train_df[['x','y']], showfliers=True)\ng0.set_title(\"Train Df Check for Outliers\")\nplt.xticks(rotation=45, ha='right')","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:46.100314Z","iopub.execute_input":"2023-08-25T14:20:46.100626Z","iopub.status.idle":"2023-08-25T14:20:46.366141Z","shell.execute_reply.started":"2023-08-25T14:20:46.100598Z","shell.execute_reply":"2023-08-25T14:20:46.364573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Deleting the outlier and the NaN row.\ntrain_df = train_df.loc[train_df['x'] <= 200]","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:46.367633Z","iopub.execute_input":"2023-08-25T14:20:46.368055Z","iopub.status.idle":"2023-08-25T14:20:46.374277Z","shell.execute_reply.started":"2023-08-25T14:20:46.368014Z","shell.execute_reply":"2023-08-25T14:20:46.373262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for outliears. \ntrain_df.describe()","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:46.375329Z","iopub.execute_input":"2023-08-25T14:20:46.376123Z","iopub.status.idle":"2023-08-25T14:20:46.404927Z","shell.execute_reply.started":"2023-08-25T14:20:46.376091Z","shell.execute_reply":"2023-08-25T14:20:46.403671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Another way to check for NaNs\ntrain_df[train_df['y'].isna()]","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:46.406873Z","iopub.execute_input":"2023-08-25T14:20:46.407654Z","iopub.status.idle":"2023-08-25T14:20:46.419454Z","shell.execute_reply.started":"2023-08-25T14:20:46.407618Z","shell.execute_reply":"2023-08-25T14:20:46.418127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for Outliers in the data\ng0 =sns.boxplot(data=train_df[['x','y']], showfliers=True)\ng0.set_title(\"Train DF w/o the Outliers\")\nplt.xticks(rotation=45, ha='right')","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:46.421304Z","iopub.execute_input":"2023-08-25T14:20:46.421815Z","iopub.status.idle":"2023-08-25T14:20:46.666847Z","shell.execute_reply.started":"2023-08-25T14:20:46.421776Z","shell.execute_reply":"2023-08-25T14:20:46.664916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training dataframe is clean.  ","metadata":{}},{"cell_type":"code","source":"# Training Scatter plot \nplt.figure(figsize=(8, 8))\nsns.scatterplot(data=test_df, x='x', y='y')\nplt.legend(labels=['Slope'])\nplt.title('', fontsize='14');","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:46.668595Z","iopub.execute_input":"2023-08-25T14:20:46.668961Z","iopub.status.idle":"2023-08-25T14:20:47.025468Z","shell.execute_reply.started":"2023-08-25T14:20:46.668928Z","shell.execute_reply":"2023-08-25T14:20:47.023635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test dataframe is clean.","metadata":{}},{"cell_type":"markdown","source":"### After the model runs you want to check for linear regression assumptions.\n### The first check is Linearity. This can be check before the model is run. \n### The following other Linear Assumptions will be checked after the model results:\n#### - Normality\n#### - Independent Observations\n#### - Homoscidasticity","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(4, 4))\nsns.scatterplot(data=train_df, x='x', y='y')\nplt.title('X Train Stuff vs Y Train Stuff', fontsize='14');","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:47.027116Z","iopub.execute_input":"2023-08-25T14:20:47.027587Z","iopub.status.idle":"2023-08-25T14:20:47.356959Z","shell.execute_reply.started":"2023-08-25T14:20:47.027538Z","shell.execute_reply":"2023-08-25T14:20:47.35555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Linearity Assumption:\n### - The scatter plot looks like it follows a line. Therefore Linearity Assumption is met for Linearity. ","metadata":{}},{"cell_type":"markdown","source":"# **Building an Ordinary Least Squares model**","metadata":{}},{"cell_type":"code","source":"# import the model\nfrom statsmodels.formula.api import ols\n\n# Write out formula\nols_formula = \"y ~ x\"\n\n# Build OLS, fit model to data\nOLS = ols(formula = ols_formula, data = train_df)\nmodel = OLS.fit()","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:47.358462Z","iopub.execute_input":"2023-08-25T14:20:47.358802Z","iopub.status.idle":"2023-08-25T14:20:47.37341Z","shell.execute_reply.started":"2023-08-25T14:20:47.358772Z","shell.execute_reply":"2023-08-25T14:20:47.37231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# call the summary() function on the model object to get the coefficients and more statistics about the model. \nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:47.374661Z","iopub.execute_input":"2023-08-25T14:20:47.374955Z","iopub.status.idle":"2023-08-25T14:20:47.405051Z","shell.execute_reply.started":"2023-08-25T14:20:47.374926Z","shell.execute_reply":"2023-08-25T14:20:47.403744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reading the OLS Regression Results:\n### R-squared: is a percentage of the dependent variable Y's variation. Y's R-Squared is 99.1%. \n### Adjusted R-squared is a modified version of R-squared which is dependent on the number of variables.\n### Prob (F-statistic) is checks the overall regression, which depicts the probability of null hypothesis being true.\n- Since the Prob F-Statistic is zero means that reliability of X to predicted Y. \n### AIC (Akaike’s Information Criteria): Lower AIC values indicate a better-fit model which it is not\n### BIC (Bayesian Information Criteria): \n### Prob(Omnibus): Errors are assume normal distributed or close to 1. A 0.919 is statisfied for OLS.  \n### Durbin-watson: Another assumption of OLS is of homoscedasticity. A value between 1 to 2 is preferred. Homoscedasticity is statisfied. \n### Prob(Jarque-Bera): It is supposed to agree with the results of Omnibus test. A large Jarque-Bera valus indicates that the errors are not normally distributed. \n","metadata":{}},{"cell_type":"code","source":"sns.regplot(x = \"x\", y = \"y\", data = train_df)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:47.40683Z","iopub.execute_input":"2023-08-25T14:20:47.407305Z","iopub.status.idle":"2023-08-25T14:20:47.813906Z","shell.execute_reply.started":"2023-08-25T14:20:47.407264Z","shell.execute_reply":"2023-08-25T14:20:47.812531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check the normality assumption\n### To check the normality assumption, you can create a histogram of the residuals using the histplot() function from the seaborn package.\n### Another way to check the normality function is to create a quantile-quantile or Q-Q plot. \n### Residuals are normally distributed, you would expect a straight diagonal line going from the bottom left to the upper right of the Q-Q plot. \n### You can create a Q-Q plot by using the qqplot function from the statsmodels.api package.","metadata":{}},{"cell_type":"code","source":"# Subset X variable\nX = train_df[\"x\"]\n\n# Get predictions from model\nfitted_values = model.predict(X)\n\n# Then, you can save the model residuals as a variable by using the model.resid attribute.\n\n# Calculate residuals\nresiduals = model.resid","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:47.815443Z","iopub.execute_input":"2023-08-25T14:20:47.815965Z","iopub.status.idle":"2023-08-25T14:20:47.825644Z","shell.execute_reply.started":"2023-08-25T14:20:47.815899Z","shell.execute_reply":"2023-08-25T14:20:47.823952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = sns.histplot(residuals)\nfig.set_xlabel(\"Residual Value\")\nfig.set_title(\"Histogram of Residuals\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:47.828592Z","iopub.execute_input":"2023-08-25T14:20:47.82903Z","iopub.status.idle":"2023-08-25T14:20:48.146598Z","shell.execute_reply.started":"2023-08-25T14:20:47.82899Z","shell.execute_reply":"2023-08-25T14:20:48.145606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import statsmodels.api as sm\nfig = sm.qqplot(model.resid, line = 's')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:48.148083Z","iopub.execute_input":"2023-08-25T14:20:48.14908Z","iopub.status.idle":"2023-08-25T14:20:48.421579Z","shell.execute_reply.started":"2023-08-25T14:20:48.149041Z","shell.execute_reply":"2023-08-25T14:20:48.420256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check the normality assumption passes.","metadata":{}},{"cell_type":"markdown","source":"### Check the homoscedasticity assumption: If the plot resembles a random cloud. ","metadata":{}},{"cell_type":"code","source":"fig = sns.scatterplot(x=fitted_values, y=residuals)\n\n# Add reference line at residuals = 0\nfig.axhline(0)\n\n# Set x-axis and y-axis labels\nfig.set_xlabel(\"Fitted Values\")\nfig.set_ylabel(\"Residuals\")\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:48.422959Z","iopub.execute_input":"2023-08-25T14:20:48.423306Z","iopub.status.idle":"2023-08-25T14:20:48.70433Z","shell.execute_reply.started":"2023-08-25T14:20:48.423272Z","shell.execute_reply":"2023-08-25T14:20:48.702786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check the homoscedasticity assumption: Passes.","metadata":{}},{"cell_type":"markdown","source":"# **Linear Regression using sklearn**\n","metadata":{}},{"cell_type":"code","source":"from sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error, r2_score\n#from scipy import stats\nfrom sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\nprint(\"Los Geht's!\")","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:48.706204Z","iopub.execute_input":"2023-08-25T14:20:48.706679Z","iopub.status.idle":"2023-08-25T14:20:48.713642Z","shell.execute_reply.started":"2023-08-25T14:20:48.706644Z","shell.execute_reply":"2023-08-25T14:20:48.712129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training the model","metadata":{}},{"cell_type":"code","source":"#making an obejct of the linear model\n# reg short for regression\nreg = linear_model.LinearRegression()\n\n# training the model\nreg.fit(train_df[['x']], train_df.y)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:48.715507Z","iopub.execute_input":"2023-08-25T14:20:48.715874Z","iopub.status.idle":"2023-08-25T14:20:48.736913Z","shell.execute_reply.started":"2023-08-25T14:20:48.715846Z","shell.execute_reply":"2023-08-25T14:20:48.735337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# need to reshape the array\n\ninput_value = np.array([10]).reshape(-1, 1)\n\nreg.predict(input_value)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:48.739177Z","iopub.execute_input":"2023-08-25T14:20:48.739551Z","iopub.status.idle":"2023-08-25T14:20:48.754598Z","shell.execute_reply.started":"2023-08-25T14:20:48.739518Z","shell.execute_reply":"2023-08-25T14:20:48.753314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The coefficient is m or the slope of y = mx + b \nreg.coef_","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:48.756832Z","iopub.execute_input":"2023-08-25T14:20:48.757326Z","iopub.status.idle":"2023-08-25T14:20:48.769541Z","shell.execute_reply.started":"2023-08-25T14:20:48.757283Z","shell.execute_reply":"2023-08-25T14:20:48.76847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The intercept is b of y = mx + b\nreg.intercept_","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:48.774679Z","iopub.execute_input":"2023-08-25T14:20:48.775198Z","iopub.status.idle":"2023-08-25T14:20:48.791134Z","shell.execute_reply.started":"2023-08-25T14:20:48.775166Z","shell.execute_reply":"2023-08-25T14:20:48.789696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Note that y = mx + b\ny = 1.00065638*10 + -0.10726546430097272\n\nprint(y)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:48.792956Z","iopub.execute_input":"2023-08-25T14:20:48.79334Z","iopub.status.idle":"2023-08-25T14:20:48.807201Z","shell.execute_reply.started":"2023-08-25T14:20:48.79331Z","shell.execute_reply":"2023-08-25T14:20:48.806079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Which is the same result that predict value of cell 26 outputed.","metadata":{}},{"cell_type":"markdown","source":"\n## Evaluate the model performance on the training data","metadata":{}},{"cell_type":"code","source":"### YOUR CODE HERE ###\nr_sq = reg.score(train_df[['x']], train_df.y)\nprint(\"Coefficient of determination:\", r_sq)\nY_pred = reg.predict(train_df[['x']])\nprint(\"R^2:\", r2_score(train_df.y, Y_pred))\nprint(\"MAE:\", mean_absolute_error(train_df.y,Y_pred))\nprint(\"RMSE:\",np.sqrt(mean_squared_error(train_df.y, Y_pred)))","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:48.809703Z","iopub.execute_input":"2023-08-25T14:20:48.810182Z","iopub.status.idle":"2023-08-25T14:20:48.830951Z","shell.execute_reply.started":"2023-08-25T14:20:48.810146Z","shell.execute_reply":"2023-08-25T14:20:48.829332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Making the predictions\n## Evaluate the model performance on the testing data","metadata":{}},{"cell_type":"code","source":"# Make predictions using the testing set\ny_pred = reg.predict(test_df[['x']])\nr_sq_test = reg.score(test_df[['x']], test_df.y)\nprint(\"Coefficient of determination:\", r_sq_test)\nprint(\"R^2:\", r2_score(test_df.y, y_pred))\nprint(\"MAE:\", mean_absolute_error(test_df.y,y_pred))\nprint(\"RMSE:\",np.sqrt(mean_squared_error(test_df.y, y_pred)))","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:48.83231Z","iopub.execute_input":"2023-08-25T14:20:48.832625Z","iopub.status.idle":"2023-08-25T14:20:48.851364Z","shell.execute_reply.started":"2023-08-25T14:20:48.832597Z","shell.execute_reply":"2023-08-25T14:20:48.849962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The model performance is similar across both training and test sets, suggesting that there is no bias in the model and that the model is not overfit.","metadata":{}},{"cell_type":"code","source":"# Create a `results` dataframe\nresults = pd.DataFrame(data={\"actual\": test_df[\"y\"],\n                             \"predicted\": y_pred.ravel()})\nresults[\"residual\"] = results[\"actual\"] - results[\"predicted\"]\nresults.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:48.852663Z","iopub.execute_input":"2023-08-25T14:20:48.853001Z","iopub.status.idle":"2023-08-25T14:20:48.873619Z","shell.execute_reply.started":"2023-08-25T14:20:48.852963Z","shell.execute_reply":"2023-08-25T14:20:48.872546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scatterplot to visualize predicted over actual","metadata":{}},{"cell_type":"code","source":"sns.set(style='whitegrid')\nf = plt.figure()\nf.set_figwidth(7)\nf.set_figheight(7)\nsns.regplot(x=\"actual\",\n           y=\"predicted\",\n           data=results, line_kws={\"color\": \"red\"})\nplt.ylim(0, 100)\nplt.xlim(0, 100)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:48.875995Z","iopub.execute_input":"2023-08-25T14:20:48.876715Z","iopub.status.idle":"2023-08-25T14:20:49.237089Z","shell.execute_reply.started":"2023-08-25T14:20:48.876674Z","shell.execute_reply":"2023-08-25T14:20:49.23616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the distribution of the `residuals`\nplt.hist(results[\"residual\"], bins=30)\nplt.title(\"Distribution of the residuals\")\nplt.xlabel(\"residual value\")\nplt.ylabel(\"count\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:49.23826Z","iopub.execute_input":"2023-08-25T14:20:49.239666Z","iopub.status.idle":"2023-08-25T14:20:49.561966Z","shell.execute_reply.started":"2023-08-25T14:20:49.239604Z","shell.execute_reply":"2023-08-25T14:20:49.561299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a scatterplot of `residuals` over `predicted`\nsns.scatterplot(x=\"predicted\", y=\"residual\", data=results)\nplt.axhline(0)\nplt.title(\"Scatterplot of residuals over predicted values\")\nplt.xlabel(\"predicted value\")\nplt.ylabel(\"residual value\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-25T14:20:49.563491Z","iopub.execute_input":"2023-08-25T14:20:49.564418Z","iopub.status.idle":"2023-08-25T14:20:49.862495Z","shell.execute_reply.started":"2023-08-25T14:20:49.564391Z","shell.execute_reply":"2023-08-25T14:20:49.861093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Linear Assumption is met. ","metadata":{}},{"cell_type":"markdown","source":"# **Conclusion**","metadata":{}},{"cell_type":"markdown","source":"## The following notebook is a Linear Regression Analysis and Modeling: \n### - EDA\n### - OLS Modeling\n### - Linear Regression Modeling\n### - Checking for Linearity Assumptions\n","metadata":{}},{"cell_type":"markdown","source":"# **Thank you all for reviewing this code and information**\n\n## Please comment and ask questions.\n\n## Vielen Dank und Bis später!","metadata":{}},{"cell_type":"markdown","source":"### ","metadata":{}}]}